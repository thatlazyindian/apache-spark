{"cells":[{"cell_type":"markdown","source":["# MNIST Handwritten Digit Recognition\n\nThis notebook demostrates the use of Apache Spark in learning a decision Tree. It also uses MLflow to track the learning process and give better understanding of some critical hyperparameters for tree learning algorithms. I have attached the output (csv file) of MLflow in the repository.\n\nData: MNIST Handwritten Digit Recognition.\n\nGoal: Learn to recognize digits (0-9) from images of handwriting."],"metadata":{}},{"cell_type":"markdown","source":["## Part 1: Setup and Loading MNIST Datasets"],"metadata":{}},{"cell_type":"markdown","source":["Before loading the dataset, I created a Spark ML cluster and attached the notebook to the cluster."],"metadata":{}},{"cell_type":"code","source":["# Check location of the data files\n%fs ls /databricks-datasets/mnist-digits/data-001"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/databricks-datasets/mnist-digits/data-001/mnist-digits-test.txt</td><td>mnist-digits-test.txt</td><td>11671108</td></tr><tr><td>dbfs:/databricks-datasets/mnist-digits/data-001/mnist-digits-train.txt</td><td>mnist-digits-train.txt</td><td>69430283</td></tr></tbody></table></div>"]}}],"execution_count":4},{"cell_type":"code","source":["# Load datasets and cache them. It is very crucial that we cache the datasets for faster processing.\ndata_train = spark.read.format(\"libsvm\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"/databricks-datasets/mnist-digits/data-001/mnist-digits-train.txt\");\ndata_test = spark.read.format(\"libsvm\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"/databricks-datasets/mnist-digits/data-001/mnist-digits-test.txt\");\n\ndata_train.cache();\ndata_test.cache();"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["## Part 2: Explore using Spark"],"metadata":{}},{"cell_type":"code","source":["print(\"There are {} training images and {} test images.\".format(data_train.count(), data_test.count()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">There are 60000 training images and 10000 test images.\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["# Checking the structure of the dataset\ndata_train.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- label: double (nullable = true)\n-- features: vector (nullable = true)\n\n</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["Displaying the data. Each image has the true label (the label column) and a vector of features that represent pixel intensities."],"metadata":{}},{"cell_type":"code","source":["display(data_train.limit(2))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>label</th><th>features</th></tr></thead><tbody><tr><td>5.0</td><td>List(0, 780, List(152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 260, 261, 262, 263, 264, 265, 266, 268, 269, 289, 290, 291, 292, 293, 319, 320, 321, 322, 347, 348, 349, 350, 376, 377, 378, 379, 380, 381, 405, 406, 407, 408, 409, 410, 434, 435, 436, 437, 438, 439, 463, 464, 465, 466, 467, 493, 494, 495, 496, 518, 519, 520, 521, 522, 523, 524, 544, 545, 546, 547, 548, 549, 550, 551, 570, 571, 572, 573, 574, 575, 576, 577, 578, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 676, 677, 678, 679, 680, 681, 682, 683), List(3.0, 18.0, 18.0, 18.0, 126.0, 136.0, 175.0, 26.0, 166.0, 255.0, 247.0, 127.0, 30.0, 36.0, 94.0, 154.0, 170.0, 253.0, 253.0, 253.0, 253.0, 253.0, 225.0, 172.0, 253.0, 242.0, 195.0, 64.0, 49.0, 238.0, 253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 251.0, 93.0, 82.0, 82.0, 56.0, 39.0, 18.0, 219.0, 253.0, 253.0, 253.0, 253.0, 253.0, 198.0, 182.0, 247.0, 241.0, 80.0, 156.0, 107.0, 253.0, 253.0, 205.0, 11.0, 43.0, 154.0, 14.0, 1.0, 154.0, 253.0, 90.0, 139.0, 253.0, 190.0, 2.0, 11.0, 190.0, 253.0, 70.0, 35.0, 241.0, 225.0, 160.0, 108.0, 1.0, 81.0, 240.0, 253.0, 253.0, 119.0, 25.0, 45.0, 186.0, 253.0, 253.0, 150.0, 27.0, 16.0, 93.0, 252.0, 253.0, 187.0, 249.0, 253.0, 249.0, 64.0, 46.0, 130.0, 183.0, 253.0, 253.0, 207.0, 2.0, 39.0, 148.0, 229.0, 253.0, 253.0, 253.0, 250.0, 182.0, 24.0, 114.0, 221.0, 253.0, 253.0, 253.0, 253.0, 201.0, 78.0, 23.0, 66.0, 213.0, 253.0, 253.0, 253.0, 253.0, 198.0, 81.0, 2.0, 18.0, 171.0, 219.0, 253.0, 253.0, 253.0, 253.0, 195.0, 80.0, 9.0, 55.0, 172.0, 226.0, 253.0, 253.0, 253.0, 253.0, 244.0, 133.0, 11.0, 136.0, 253.0, 253.0, 253.0, 212.0, 135.0, 132.0, 16.0))</td></tr><tr><td>0.0</td><td>List(0, 780, List(127, 128, 129, 130, 131, 154, 155, 156, 157, 158, 159, 181, 182, 183, 184, 185, 186, 187, 188, 189, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 289, 290, 291, 292, 293, 294, 295, 296, 297, 300, 301, 302, 316, 317, 318, 319, 320, 321, 328, 329, 330, 343, 344, 345, 346, 347, 348, 349, 356, 357, 358, 371, 372, 373, 374, 384, 385, 386, 399, 400, 401, 412, 413, 414, 426, 427, 428, 429, 440, 441, 442, 454, 455, 456, 457, 466, 467, 468, 469, 470, 482, 483, 484, 493, 494, 495, 496, 497, 510, 511, 512, 520, 521, 522, 523, 538, 539, 540, 547, 548, 549, 550, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 622, 623, 624, 625, 626, 627, 628, 629, 630, 651, 652, 653, 654, 655, 656, 657), List(51.0, 159.0, 253.0, 159.0, 50.0, 48.0, 238.0, 252.0, 252.0, 252.0, 237.0, 54.0, 227.0, 253.0, 252.0, 239.0, 233.0, 252.0, 57.0, 6.0, 10.0, 60.0, 224.0, 252.0, 253.0, 252.0, 202.0, 84.0, 252.0, 253.0, 122.0, 163.0, 252.0, 252.0, 252.0, 253.0, 252.0, 252.0, 96.0, 189.0, 253.0, 167.0, 51.0, 238.0, 253.0, 253.0, 190.0, 114.0, 253.0, 228.0, 47.0, 79.0, 255.0, 168.0, 48.0, 238.0, 252.0, 252.0, 179.0, 12.0, 75.0, 121.0, 21.0, 253.0, 243.0, 50.0, 38.0, 165.0, 253.0, 233.0, 208.0, 84.0, 253.0, 252.0, 165.0, 7.0, 178.0, 252.0, 240.0, 71.0, 19.0, 28.0, 253.0, 252.0, 195.0, 57.0, 252.0, 252.0, 63.0, 253.0, 252.0, 195.0, 198.0, 253.0, 190.0, 255.0, 253.0, 196.0, 76.0, 246.0, 252.0, 112.0, 253.0, 252.0, 148.0, 85.0, 252.0, 230.0, 25.0, 7.0, 135.0, 253.0, 186.0, 12.0, 85.0, 252.0, 223.0, 7.0, 131.0, 252.0, 225.0, 71.0, 85.0, 252.0, 145.0, 48.0, 165.0, 252.0, 173.0, 86.0, 253.0, 225.0, 114.0, 238.0, 253.0, 162.0, 85.0, 252.0, 249.0, 146.0, 48.0, 29.0, 85.0, 178.0, 225.0, 253.0, 223.0, 167.0, 56.0, 85.0, 252.0, 252.0, 252.0, 229.0, 215.0, 252.0, 252.0, 252.0, 196.0, 130.0, 28.0, 199.0, 252.0, 252.0, 253.0, 252.0, 252.0, 233.0, 145.0, 25.0, 128.0, 252.0, 253.0, 252.0, 141.0, 37.0))</td></tr></tbody></table></div>"]}}],"execution_count":10},{"cell_type":"code","source":["import numpy as np\nimport matplotlib.image as mpimg\nimport math\nfrom matplotlib import pyplot as plt\n\n# Function to render images stored in the dataset.\ndef show_images(data):\n  # Each image is supposed to be tuple.\n  # the first element of the tuple is a 780 sparse vector, corresponding to features in the MNIST dataset.\n  # the second element is an integer, corresponding to the label or predicted digit\n  # in the following, we display the list of pictures in four-picture rows along with their labels.\n  # don't show too many pictures with this function.\n  # e.g. show_images([(r.features, r.label) for r in df.take(4)])\n \n  fig = plt.figure()\n  columns = 4\n  rows = math.ceil(len(data)/4) # determine how many rows we need\n  \n  # ax enables access to manipulate each of subplots\n  ax = []\n\n  for i in range(len(data)):\n      # the image is an array of 28x28 (=784) gray scale pixels. but the data is an 780 array. We need to pad it, \n      # convert it to float values, and reshape it to 28x28 matrices.\n      img = np.array(np.pad(data[i][0],(0,784-len(data[i][0])),'constant',constant_values=(0,0)), dtype='float').reshape((28, 28))\n      # create subplot and append to ax\n      ax.append(fig.add_subplot(rows, 4, i+1) )\n      ax[-1].set_title(str(int(data[i][1])))  # set title for the last image to its label.\n      plt.imshow(img,cmap='gray') # render the image\n      plt.axis('off') # turn off axies\n  \n  # display the images\n  display(fig)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["show_images([(r.features, r.label) for r in data_train.take(4)])"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["## Part 3: Training a base Decision Tree Classifier"],"metadata":{}},{"cell_type":"code","source":["# Import the ML classification, evaluator, indexer, and pipeline classes \nfrom pyspark.ml.classification import DecisionTreeClassifier, DecisionTreeClassificationModel\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml import Pipeline"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["# StringIndexer: Read input column \"label\" (digits) and annotate them as categorical values.\nindexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\")\n# DecisionTreeClassifier: Learn to predict column \"indexedLabel\" using the \"features\" column.\ndtc = DecisionTreeClassifier(labelCol=\"indexedLabel\")\n# Chain indexer + dtc together into a single ML Pipeline.\npipeline = Pipeline(stages=[indexer, dtc])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"code","source":["# First have a look at the accuracy of base model\npipelineModel = pipeline.fit(data_train)\npredictions = pipelineModel.transform(data_test)\nevaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\naccuracy = evaluator.evaluate(predictions)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"code","source":["print(\"Accuracy = %g\" % (accuracy))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy = 0.704787\n</div>"]}}],"execution_count":17},{"cell_type":"markdown","source":["Using a simple decision tree classifier, we get an accuracy of 70%. Next, let's visualize these results before training a cross validated model using MLflow."],"metadata":{}},{"cell_type":"markdown","source":["### Visualize Results"],"metadata":{}},{"cell_type":"code","source":["correct_prediction = predictions.filter(predictions['label'] == predictions['prediction'])\nshow_images([(r.features, r.prediction) for r in correct_prediction.sample(False, 0.1, 0).take(8)])"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["incorrect_prediction = predictions.filter(predictions.label != predictions.prediction)\nshow_images([(r.features, r.prediction) for r in incorrect_prediction.sample(False, 0.1, 0).take(8)])"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["## Step 4: Training a Decision Tree Classifier with Automated MLflow Tracking for CrossValidator model tuning"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\ngrid = ParamGridBuilder() \\\n  .addGrid(dtc.maxDepth, [2, 3, 4, 5, 6, 7, 8]) \\\n  .addGrid(dtc.maxBins, [2, 4, 8]) \\\n  .build()\n\ncv = CrossValidator(estimator=pipeline, evaluator=evaluator, estimatorParamMaps=grid, numFolds=3)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":23},{"cell_type":"code","source":["import mlflow\nimport mlflow.mleap\nwith mlflow.start_run():\n  cvModel = cv.fit(data_train)\n  mlflow.set_tag('owner_team', 'UX Data Science') # Logs user-defined tags\n  test_metric = evaluator.evaluate(cvModel.transform(data_test))\n  mlflow.log_metric('test_' + evaluator.getMetricName(), test_metric) # Logs additional metrics\n  mlflow.mleap.log_model(spark_model=cvModel.bestModel, sample_input=data_test, artifact_path='best-model') # Logs the best model via mleap"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">MLlib will automatically track trials in MLflow. After your tuning fit() call has completed, view the MLflow UI to see logged runs.\n</div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["<b> Conclusion </b>\n\nUsing the MLflow, I found the following parameters for the best model:\n- maxDepth: 8\n- maxBins: 4\n\nI have attached a csv file showing the results of all 21 models.\n\nFuture steps to improve model:\nWe can create new images by rotating the current images by 180 degress and double our training data. This would help in better training of the model and provide better accuracy."],"metadata":{}}],"metadata":{"name":"Digit Recognition using Apache Spark","notebookId":1561576955521664},"nbformat":4,"nbformat_minor":0}
